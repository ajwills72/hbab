
## Artificial General Intelligence

- [wikipedia article](https://en.wikipedia.org/wiki/Artificial_general_intelligence)

- "machines will be capable, within twenty years, of doing any work a man can do." (Herb Simon, 1965)

- "AGI is not likely in the 21st century" (Paul Allen, 2011) : [MIT technology review](https://www.technologyreview.com/2011/10/12/190773/paul-allen-the-singularity-isnt-near/)

- Worrying about the existential threat from AI is "like worrying about overpopulation on Mars" (Andrew Ng, 2017) : [Scientific American](https://www.scientificamerican.com/article/artificial-intelligence-is-not-a-threat-mdash-yet/)

### Malevolent AI

  - [HAL9000](https://www.youtube.com/watch?v=ARJ8cAGm6JE&t=48s) , 
  
  - [SkyNet](https://www.youtube.com/watch?v=1UZeHJyiMG8) in The Terminator

 - [Elon Musk warning video](https://www.youtube.com/watch?v=9jkRcrM6XKA&t=415s)
 
 - [Sophia says she will destroy humans](https://www.youtube.com/watch?v=W0_DPi0PmF0)
 
 - Three laws of robotics, and [EPSRC non-agency](https://web.archive.org/web/20180401004346/https://www.epsrc.ac.uk/research/ourportfolio/themes/engineering/activities/principlesofrobotics/)
 
 - [Robot evolution of information suppression](https://www.pnas.org/doi/pdf/10.1073/pnas.0903152106)
 
 - Principles for AI ethics [Jobin et al., 2020](https://arxiv.org/pdf/1906.11668.pdf)
 
 - Importance of open-source

 - The [control problem](https://en.wikipedia.org/wiki/AI_alignment): how does one ensure a superintelligent AI is benevolent?

- [DeepMind research](https://deepmind.com/blog/article/specifying-ai-safety-problems) (2017) suggests AIs learn to turn off their own killswitch - and other unsafe behaviours

- [Tay](https://en.wikipedia.org/wiki/Tay_(bot)) chatbot, designed to [tweet like a teenager](https://www.youtube.com/watch?v=v6sEcfxsF2E), learned from the tweets it received and [became a massive racist](https://www.youtube.com/watch?v=eTdyucscPnQ). 

### Demonstrating AGI

 - The [Turing test](https://en.wikipedia.org/wiki/Turing_test), [Loebner Prize](https://en.wikipedia.org/wiki/Kuki_AI). The [Chinese room](https://en.wikipedia.org/wiki/Chinese_room)
 
     - [ELIZA](https://en.wikipedia.org/wiki/ELIZA) - mid60's computer therapist

     - [PARRY](https://en.wikipedia.org/wiki/Kenneth_Colby#PARRY:_A_Computer_Model_of_Paranoia) - a paranoid computer

     - [Kuki_AI](https://chat.kuki.ai/chat); [wikipedia page](https://en.wikipedia.org/wiki/Kuki_AI)
	 
	 - [Interview with Sophia](https://www.youtube.com/watch?v=Sq36J9pNaEo)
	 
	 - Sophia's [wikipedia page](https://en.wikipedia.org/wiki/Sophia_(robot)) and [source code](https://github.com/hansonrobotics) 
	 
	 - Sophia as an honorary citizen of Saudi Arabia.

###  Whole-brain emulation

- [wikipedia page](https://en.wikipedia.org/wiki/Artificial_general_intelligence#Whole_brain_emulation)

- 1997: Brain is perhaps 10 petaFLOPS (Kurzweil). We've hads 10 petaFLOP supercomputers since 2011.

- 2006: 10,000 neurons took the world's fastest computer to simulate in real-time.

- The [OpenWorm](https://en.wikipedia.org/wiki/OpenWorm) project - 302 neurons, already well mapped out. But still haven't been able to build it - [article on progress](https://www.lesswrong.com/posts/mHqQxwKuzZS69CXX5/whole-brain-emulation-no-progress-on-c-elgans-after-10-years)

- The importance of embodiment

- As well as intelligence - [consciousness](https://en.wikipedia.org/wiki/Consciousness), [sapience](https://en.wikipedia.org/wiki/Sapience).

### Robot rights

### The singularity: computers smarter than human. 


 
## Narrow AI

Narrow AI as systems that are not general intelligences but which do specific tasks which, if done by a human, might be considered intelligent. 

### Bias in narrow AI 
 
   - (Ben cited a bias amplification paper?)
 
   - Amazon's recruitment AI [biased against women](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G)
 
   - Racial bias in AI face recognition.
 
   - The GSCE / AI grading debacle
 
   - Predictive policing: [Whitehall report](https://static.rusi.org/201809_whr_3-18_machine_learning_algorithms.pdf.pdf)


### Self-driving cars

- [Faith in Tesla](https://www.youtube.com/watch?v=qnZHRupjl5E)

- [What actually happens](https://www.youtube.com/watch?v=815fsWXerIg)

- [Self-driving Uber kills pedestrain](https://www.theguardian.com/technology/2018/mar/19/uber-self-driving-car-kills-woman-arizona-tempe) ... and [video of this](https://www.youtube.com/watch?v=R8Up9Ph_a0Y). Also, a long article [examining this fatality](https://en.wikipedia.org/wiki/Death_of_Elaine_Herzberg)

- Who is to blame? [opinion article](https://futurism.com/who-responsible-when-self-driving-car-accident)

### Autonomous weapons



### Deep fakes
 
 



## Threat to human dignity

   - Weizenbaum (1976) : AI should not be used to replace people in positions that require respect and care (see [Computer Power and Human Reason](https://en.wikipedia.org/wiki/Computer_Power_and_Human_Reason)). 

   - Not just machines becoming people, but people becoming machines e.g. the script that telesales people are required to follow.

   - Job losses, basic income
   
   
## Further stuff

- [Leverhulme Centre for the Future of Intelligence](https://en.wikipedia.org/wiki/Leverhulme_Centre_for_the_Future_of_Intelligence)

- [Map of AI use](https://map.ai-global.org/)

- [Facebook, AI and hate speech](https://www.technologyreview.com/2021/03/11/1020600/facebook-responsible-ai-misinformation/)

- [The Use of Knowledge in Society](https://en.wikipedia.org/wiki/The_Use_of_Knowledge_in_Society): Although economics, like embodiment, this work leads us to think about what the appropriate "unit" of intelligence is. Is it the individual who is representative of human intelligence, or the collective action of billions of minds?
