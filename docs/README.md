# How To Build A Brain

**Summary**: A five two-hour seminar introduction to the brain-inspired nature of artificial intelligence (AI), ending with a discussion of moral and ethical issues. This course has been designed as an option for final-year psychology undergraduates, and hence assumes no prior knowledge of AI (or maths beyond GCSE). 

## Course outline

Machines have now taught themselves to beat humans at playing many games, including those considered to involve skill (classic video games) or intelligence (Chess, Go, Jeopardy). At the same time, these machines pretty much suck at apparently simple tasks like classifying everyday objects (“It’s a cat”) or walking. In many cases, the design of these machines is inspired by the structure of the human brain. In understanding this area more fully, we hope to better understand ourselves, and to be better able to specify what it means to be human, beyond those aspects of our abilities that can now be automated. It also raises deep philosophical and ethical questions about the future of the human race as we increasingly move from automating manual labour to automating intellectual labour. 

In this series of five two-hour seminars, we’ll trace the origins of how psychology and neuroscience have informed artificial intelligence, focussing on major breakthroughs from early beginnings in the 1940s, through a second wave of research in the 1980s and 90s, and to the recent dramatic achievements in brain-inspired AI in the last decade. We’ll also consider the ethical and philosophical issues these advancements raise. 

If you’d like to know more about these topics, a great place to start would be to watch the award-winning movie AlphaGo – it’s available for free on [youtube](https://www.youtube.com/watch?v=WXuK6gekU1Y). Or, for a more fictionalized account of the possible future of this field, you could watch the movies  [Ex Machina](https://en.wikipedia.org/wiki/Ex_Machina_(film)) or [Her](https://en.wikipedia.org/wiki/Her_(film)).  

## Content

- **History and core concepts** - from Ancient Greece to backprop. [slides](core.pdf), [notes](core.md), [worksheet](https://colab.research.google.com/drive/18GMjdVlSd8D7sdZmSFNq7wA7qRerE59Z?usp=sharing#scrollTo=K_3w9V669UVh)

- **Perception** - rise of the convolutional neural networks. [slides](perception.pdf), [notes](perception.md)

- **Philosophy, including ethics**. [slides](ethics.pdf), [notes](ethics.md)

## Assessment 

As this is a course on AI, I couldn't resist sharing a couple of examples of the GPT-3 AI system writing essays - for the [Guardian](https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3) newspaper, and as part of a [Medium](https://sauravkumr.medium.com/i-told-gpt-3-to-write-an-essay-about-the-future-of-ai-93c9d5f47e61) article. Make sure _you_ pass the Turing test and convince me your essay was written by a human! 

More seriously, here's some extensive [essay guidance](essay-guidance.pdf) for these assessments.

### Main period

1. Critically review the development of brain-like artificial intelligence systems for perception, from the Mark 1 Perceptron to modern convolutional networks. What innovations took us from one to the other? How did the systems improve, and what is still left to do?

2. The development of fully autonomous vehicles is one goal of artificial intelligence research. What are the ethical and societal issues surrounding the achievement of that goal? 

### Referral period

1. Critically review the development of brain-like artificial intelligence systems for action, from TD-Gammon to AlphaGo. What changed, and what is still left to do?

2. One consequence of artificial intelligence research may be the development of autonomous weapons. What ethical and societal issues does this raise?


